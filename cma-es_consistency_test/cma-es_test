import numpy as np
import cma
import matplotlib.pyplot as plt

# functions to optimize
def rosenbrock(x):
    return np.sum(100.0 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)

def rastrigin(x):
    d = len(x)
    return 10*d + np.sum(x**2 - 10*np.cos(2*np.pi*x))

# arbitrary starting point
x0 = np.array([0, 0])

#maximum number of function evaluations for each run
max_evals = 1000

# step size for shifting the starting point
delta_i = 0.1

# number of runs to perform
num_runs = 10

# store the optimization results
results = np.zeros(num_runs)

# Perform the optimization runs
for i in range(num_runs):
    # Define the shifted starting point
    x0_shifted = x0 + delta_i * i
    # If we want noise
    # x0_shifted = x0 + delta_i * i + np.random.normal(0, 0.1, size=len(x0))
    
    # Use algorithm to optimize the function
    # could aslo add params to make noise
    # options = {'maxfevals': max_evals, 'popsize': 8, 'sigma': 0.1 + np.random.normal(0, 0.01)}
    res = cma.fmin(rastrigin, x0_shifted, 0.1, {'maxfevals': max_evals})
    
    
    # gets distance to the local maximum
    # for rose brock as there is a there is a min of 0 where all inputs are 1
    # results[i] = np.linalg.norm(res[0] - np.ones_like(x0))
    # for rastagin a global minimum where all input are equal to 1
    results[i] = np.linalg.norm(res[0])
    
# Calculate mean distance and std deviation
mean_distance = np.mean(results)
std_distance = np.std(results)

# Print the results
# print("Mean distance to local maximum: {:.4f}".format(mean_distance))
# print("Standard deviation of distances: {:.4f}".format(std_distance))

# # Plot the results
# fig, ax = plt.subplots()
# ax.plot(np.arange(num_runs) * delta_i, results, 'o-', label='CMA-ES')
# ax.axhline(y=mean_distance, color='gray', linestyle='--', label='Mean distance')
# ax.set_xlabel('Starting point')
# ax.set_ylabel('Distance to local maximum')
# ax.legend()
# plt.show()